<properties>
    <java.version>1.8</java.version>
    <spring-boot.version>2.7.18</spring-boot.version>
    <confluent.version>7.5.1</confluent.version> <!-- Adjust according to your Confluent version -->
</properties>

<dependencies>
    <!-- Spring Boot Starter Web (for Rest API) -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>

    <!-- Spring Boot Starter Kafka -->
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
        <version>2.8.0</version> <!-- Use a compatible version with your Spring Boot version -->
    </dependency>

    <!-- Confluent Kafka Avro Serializer for Schema Registry -->
    <dependency>
        <groupId>io.confluent</groupId>
        <artifactId>kafka-avro-serializer</artifactId>
        <version>${confluent.version}</version>
    </dependency>

    <!-- Confluent JSON Schema Serializer -->
    <dependency>
        <groupId>io.confluent</groupId>
        <artifactId>kafka-json-schema-serializer</artifactId>
        <version>${confluent.version}</version>
    </dependency>

    <!-- Spring Boot Starter for JSON Schema -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-json</artifactId>
    </dependency>

    <!-- Jackson (used for JSON serialization/deserialization) -->
    <dependency>
        <groupId>com.fasterxml.jackson.core</groupId>
        <artifactId>jackson-databind</artifactId>
    </dependency>

    <!-- Spring Boot Starter Actuator (Optional for monitoring) -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
</dependencies>

------------------------------
<dependencies>
    <!-- Spring Kafka -->
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
        <version>2.8.0</version> <!-- Ensure the version is compatible with your Spring Boot version -->
    </dependency>

    <!-- Confluent Kafka Client -->
    <dependency>
        <groupId>io.confluent</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>7.0.1</version> <!-- Ensure the version is compatible with Confluent Kafka -->
    </dependency>

    <!-- Confluent Schema Registry -->
    <dependency>
        <groupId>io.confluent</groupId>
        <artifactId>kafka-schema-registry-client</artifactId>
        <version>7.0.1</version> <!-- Ensure the version is compatible with your Schema Registry version -->
    </dependency>

    <!-- Confluent Kafka Avro Serializer for Schema Registry -->
    <dependency>
        <groupId>io.confluent</groupId>
        <artifactId>kafka-avro-serializer</artifactId>
        <version>7.0.1</version> <!-- Ensure the version is compatible -->
    </dependency>

    <!-- Jackson for JSON (for schema registry support) -->
    <dependency>
        <groupId>com.fasterxml.jackson.core</groupId>
        <artifactId>jackson-databind</artifactId>
        <version>2.13.3</version> <!-- Ensure the version is compatible -->
    </dependency>
</dependencies>


spring:
  kafka:
    bootstrap-servers: <your-cluster-bootstrap-server>
    consumer:
      group-id: your-consumer-group-id
      auto-offset-reset: earliest
      security:
        protocol: SASL_SSL
        sasl:
          mechanism: PLAIN
          jaas:
            config: org.apache.kafka.common.security.plain.PlainLoginModule required \
              username="<your-api-key>" \
              password="<your-api-secret>";
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        schema.registry.url: <your-schema-registry-url>  # Example: https://<your-cluster-id>.us-west1.gcp.confluent.cloud
        basic.auth.credentials.source: USERINFO
        basic.auth.user.info: <your-api-key>:<your-api-secret>

    producer:
      acks: all
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      security:
        protocol: SASL_SSL
        sasl:
          mechanism: PLAIN
          jaas:
            config: org.apache.kafka.common.security.plain.PlainLoginModule required \
              username="<your-api-key>" \
              password="<your-api-secret>";
      properties:
        schema.registry.url: <your-schema-registry-url>
        basic.auth.credentials.source: USERINFO
        basic.auth.user.info: <your-api-key>:<your-api-secret>













import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.listener.ConcurrentMessageListenerContainer;
import org.springframework.kafka.listener.MessageListener;
import org.springframework.kafka.listener.MessageListenerContainer;
import org.springframework.kafka.listener.config.ConcurrentMessageListenerContainerConfig;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaProducerConfig {

    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate() {
        Map<String, Object> producerProps = new HashMap<>();
        producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "<your-cluster-bootstrap-server>");
        producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class);
        producerProps.put("security.protocol", "SASL_SSL");
        producerProps.put("sasl.mechanism", "PLAIN");
        producerProps.put("sasl.jaas.config", "org.apache.kafka.common.security.plain.PlainLoginModule required username='<your-api-key>' password='<your-api-secret>';");
        producerProps.put("schema.registry.url", "<your-schema-registry-url>");
        producerProps.put("basic.auth.credentials.source", "USERINFO");
        producerProps.put("basic.auth.user.info", "<your-api-key>:<your-api-secret>");

        DefaultKafkaProducerFactory<String, Object> producerFactory = new DefaultKafkaProducerFactory<>(producerProps);
        return new KafkaTemplate<>(producerFactory);
    }
}








import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.listener.ConcurrentMessageListenerContainer;
import org.springframework.kafka.listener.MessageListener;
import org.springframework.kafka.listener.MessageListenerContainer;
import org.springframework.kafka.listener.config.ConcurrentMessageListenerContainerConfig;

import java.util.HashMap;
import java.util.Map;

@Configuration
@EnableKafka
public class KafkaConsumerConfig {

    @Bean
    public ConcurrentMessageListenerContainer<String, Object> messageListenerContainer() {
        Map<String, Object> consumerProps = new HashMap<>();
        consumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "<your-cluster-bootstrap-server>");
        consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, "your-consumer-group-id");
        consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, KafkaAvroDeserializer.class);
        consumerProps.put("security.protocol", "SASL_SSL");
        consumerProps.put("sasl.mechanism", "PLAIN");
        consumerProps.put("sasl.jaas.config", "org.apache.kafka.common.security.plain.PlainLoginModule required username='<your-api-key>' password='<your-api-secret>';");
        consumerProps.put("schema.registry.url", "<your-schema-registry-url>");
        consumerProps.put("basic.auth.credentials.source", "USERINFO");
        consumerProps.put("basic.auth.user.info", "<your-api-key>:<your-api-secret>");

        DefaultKafkaConsumerFactory<String, Object> consumerFactory = new DefaultKafkaConsumerFactory<>(consumerProps);
        ConcurrentMessageListenerContainerConfig config = new ConcurrentMessageListenerContainerConfig("your-topic", consumerFactory);

        return new ConcurrentMessageListenerContainer<>(config);
    }
}




import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

@Component
public class KafkaProducer {

    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;

    public void sendMessage(String topic, String message) {
        kafkaTemplate.send(topic, message);
    }
}



import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
public class KafkaConsumer {

    @KafkaListener(topics = "your-topic", groupId = "your-consumer-group-id")
    public void listen(String message) {
        System.out.println("Received Message: " + message);
    }
}









